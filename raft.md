# 可理解的一致性算法研究(raft)
> In search of an Understandable Consensus Algorithm (Extended Version)

## 摘要

Raft 是一种用来管理日志复制的一致性算法. 它与 Paxos 是等效的, 同时在性能上也相近,但是它采用了不同的结构;这使得 Raft 更容易理解, 也更易于建立实际的系统。为了便于理解，Raft 将一致性算法分为了几个部分，例如领导选取 (leader selection)，日志复制(log replication) 和安全性 (safety), 同时它**使用了更强的一致性来减少了必须需要考虑的状态**。从用户学习的结果来看, Raft 比 Paxos 更容易上手. Raft 还引入了一种新的机制动态改变集群成员，它使用**重叠大多数(overlapping majorities)**来保证安全。


## 1 介绍

一致性算法允许一组机器像一个整体一样工作，即使其中的一些机器失效也能正常提供服务.正是因为这样的特点，他们在构建大规模可靠的软件系统中扮演了关键角色。在过去的数十年中 , Paxos 统治着有关一致性算法的讨论: 大多数一致性算法的实现都基于它或者受它影响, 并且 Paxos 也成了教授一致性知识的主要载体.

不幸的是, 尽管在降低它的复杂性方面做了许多努力, Paxos 依旧很难理解. 并且, Paxos 需要经过复杂的修改才能应用于实际系统. 这些导致了系统构建者和学生都十分头疼.

在被 Paxos 折磨之后， 我们开始寻找一种在系统构建和教学上表现更好的一致性算法. 我们的首要目标是让它易于理解: 我们能不能定义一种面向实际系统并且比 Paxos 更容易学习的的一致性算法呢? 并且, 我们希望这种算法能凭直觉就能明白, 这对于一个系统构建者来说是十分必要的. 让一个算法工作起来很重要, 知道它是如何工作的更重要.

我们工作的结果是一种新的一致性算法, 叫做 Raft. 在设计 Raft 的过程中我们应用了许多专门的技巧来使其便于理解, 包括算法分解(分为领导选取--leader selection, 日志复制--log replication 和安全性--safety) 和状态空间减少(state space reduction) (相对于 Paxos, Raft 减少了不确定性和服务器之间状态不一致的可能). 一项在两所学校的43个学生中进行的研究表明, Raft 比 Paxos 明显要更容易理解:在学习了两种算法之后, 其中的33个学生能够更好的回答 Raft 的问题.

Raft 算法和已有的算法在某些地方很相似(主要是 Oki 和 Liskov 的 Viewstamped Replication).但是 Raft 有几个新的特性：

*    强领导 (Strong Leader): Raft 强化了领导的作用. 例如, 日志条目只从领导者发往其他服务器. 这样就简化了对日志复制的管理, 使得 Raft 更易于理解.
*    领导选取 (Leader Selection): Raft 使用随机定时器来选取领导者. 这种方法仅仅是在所有一致性算法都需要的心跳机制上增加了一点变化，然而它却使得解决冲突更简单和快速。
*   成员变化 (Membership Change): Raft 为了调整集群中成员使用了新的**联合一致性(joint consensus)的方法, 这种方法中大多数不同配置的机器在转换关系的时候会交迭(overlap).** 这使得在配置改变的时候, 集群仍然能够正常运作.

我们认为, raft 在教学和实际应用方面比 Paxos 和其他算法表现更好. 它比其他算法更简单, 更容易理解；它满足一个实际系统的所有需求；它拥有许多开源的实现并且被许多公司使用；它的安全性已经被证实；并且它的效率也具有竞争力。

这篇论文剩下的部分会讲如下内容：复制状态机 (replicated state machine) 问题 (第2节), 讨论 Paxos 的优缺点(第3节), 描述我们对可理解性的一般方法(第4节), 陈述 Raft 一致性算法(第5~8节), 评价 Raft 算法(第9节), 对相关工作的讨论(第10节).


## 2 复制状态机 (Replicated State Machine)

一致性算法是在复制状态机的背景下提出来的. 在这个方法中，一组服务器中的所有状态机计算并获取同样的状态, 即使有一些服务器崩溃了, 这组服务器(作为一个整体)仍然能继续运行. 复制状态机在分布式系统中被用于解决许多容错问题, 例如 GFS, HDFS 还有 RAMCloud 这些大规模的系统都有一个单独的集群领导，通常用一个单独的复制状态机来进行领导选取和存储配置信息来应对领导者的崩溃. 使用复制状态机的例子包括 Chubby 和 ZooKeeper.

![Replicated State Machine](https://raw.githubusercontent.com/21moons/memo/master/res/img/raft_1.jpg)

<font size=2>图1: 复制状态机的架构。一致性算法管理复制日志, 它包括来自客户的状态机命令。所有的状态机都处理相同的命令序列，因此会得到相同的执行结果</font>

如图-1所示，复制状态机是通过复制日志来实现的。每台服务器保存的日志都是相同的，日志中包含一系列的命令，状态机会执行相同顺序的命令。因为每一台计算机的状态机都是确定的(唯一的输入对应唯一的输出)，所以所有的状态机都次都会计算出相同的状态，并最终得到相同的结果.

一致性算法的工作是保证复制日志一致. 服务器上的一致性模块接受客户端的命令并将命令加入复制日志. 它和其他服务器上的一致性模块进行通信来确保每一个日志最终包含相同的请求序列, 即使有一些服务器宕机. 一旦这些命令被正确的复制了, 每一个服务器的状态机都会按同样的顺序去执行它们, 然后将结果返回给客户端. 最终, 这些服务器看起来就像一台高可靠的状态机.

应用于实际系统的一致性算法一般有以下特性:


* 确保安全性(从来不会返回一个错误的结果), 即使在所有的非拜占庭(Non-Byzantine)情况下, 包括网络延迟、分区、丢包、冗余和乱序。
* 高可用性，只要集群中的大部分机器能运行，可以互相通信并且与客户端通信，这个集群就可用。因此，一个拥有 5 台机器的集群可以容忍其中任意 2 台机器的失败(fail)。服务器停止工作了我们就认为它失败(fail)了，没准一会当它们拥有稳定的存储时就能从中恢复过来，重新加入到集群中。
* 不依赖时序保证一致性，时钟错误和极端情况下的消息延迟在最坏的情况下才会引起可用性问题。
* 通常情况下，一条命令能够在大多数节点对远程调用作出响应时就完成，少部分慢的机器不会影响系统的整体性能。


## 3 Paxos 算法的不足

在过去的10年中, Leslie Lamport 的 Paxos 算法几乎已经成为了一致性算法的代名词:它是授课中最常见的算法, 同时也是许多其他一致性算法实现的源头.Paxos 首先定义了一个能够达成单一决策一致的协议，例如一个单一复制日志条目(single replicated log entry). 我们把这个子集叫做单一决策 Paxos(single-decree Paxos).之后 Paxos通过组合多个这种协议来完成一系列的决策，例如一个日志（multi-Paxos).Paxos 确保安全性和活跃性(liveness), 并且它支持集群成员的变更. 它的正确性已经被证明, 通常情况下也很高效.

不幸的是, Paxos 有两个致命的缺点. 第一个是 Paxos 太难以理解. 它的完整解释晦涩难懂;很少有人能完全理解, 只有少数人成功的读懂了它. 因此大家尝试用一些简单的术语来描述它. 尽管这些解释都专注于单一决策问题, 但仍具有挑战性. 在 NSDI 2012 会议上的一次非正式调查显示, 我们发现大家对 Paxos 都感到不满意, 其中甚至包括一些有经验的研究员. 我们自己也曾深陷其中, 我们在读了几篇简化版的说明文档并且设计了我们自己的算法之后才完全理解了 Paxos, 而整个过程花费了将近一年的时间.

我们假定 Paxos 的晦涩是因为它将单一决策方案作为它的基础. 单一决策(Single-decree Paxos) 是晦涩且微妙的: 它被划分为两个没有简单直观解释的阶段，并且难以独立理解. 正因为如此, 它不能很直观的让我们知道为什么单一决策协议能够工作. 为多决策 Paxos 添加的规则又添加了额外的复杂性和精巧性.我们相信多次决策达成一致的问题能够分解为其它更直观的方式.

Paxos 的第二个缺点是它难以在实际环境中实现. 其中一个原因是, 对于多决策 Paxos (multi-Paxos)算法, 大家还没有达成广泛的一致. Lamport 的描述大部分都是有关于单一决策 Paxos (single-decree Paxos); 他仅仅描述了实现多决策的可能的方法, 但缺少许多细节. 有许多实现 Paxos 和优化 Paxos 的尝试, 但是他们都和 Lamport 的描述有些出入, 并且彼此也没有多少相同之处. 例如,Chubby 实现的是一个类似 Paxos 的算法, 但是在许多场景下的处理细节没有公开.

另外, Paxos 的架构对于实际实现来说也是不够的, 这是单一决策问题分解带来的又一个问题. 例如, 选择独立的日志条目集合然后将它们合并到顺序日志中没有什么好处, 它仅仅增加了复杂性. 相比之下, 围绕着日志来设计一个系统是更简单、更高效的: 新日志按照严格的顺序添加到日志中去. 另一个问题是, Paxos 使用对等的点对点方法作为它的核心(尽管它最终提出了一种弱领导者的形式来优化性能). 这种方法在只有一个决策被制定的情况下才有意义, 但是很少有现实中的系统使用这种方法. 如果要做一系列决策, 先选择一个领导人, 再由领导人来协调是更简单有效的方法.

因此, 实际系统中的一致性算法实现和 Paxos 算法都相差很大. 所有基于 Paxos 的实现都会遇到很多问题, 然后由此衍生出了许多与 Paxos 差异巨大的架构. 这是耗时且容易出错的, 理解Paxos的困难又加剧了问题. Paxos 算法在逻辑上是完备的, 但是实现上的困难使其理论上的完美毫无价值. 来自 Chubby 实现者的以下评论非常具有代表性:

> Paxos 算法的描述与实际实现之间存在巨大的鸿沟…最终的系统往往建立在一个没有被证明的算法之上.

正因为存在这些问题, 我们认为 Paxos 不仅对于系统的构建者来说不友好, 同时也不利于教学. 鉴于一致性算法对于大规模软件系统的重要性, 我们决定试着来设计一种比 Paxos 更好的一致性算法. Raft 就是这次尝试的结果.

## 4 易于理解的设计

Raft 需要达成以下几个目标：

* 它必须为系统构建提供一个详细的、可行的基础，这样便可以大量减少开发者的设计工作;
* 它必须在所有情况下都能保证安全,在典型的应用场景下保证可用;
* 它对于常规操作必须高效;
* 最重要的目标是：易于理解，它必须使得大多数人能够很容易的理解;
* 另外，它能让开发者有一个直观的认识，这样才能使系统构建者们去对它进行扩展, 而这种扩展是不可避免的.

在设计 Raft 的过程中, 我们不得不在许多点中做出选择. 当面临这种情况时，我们通常会基于可理解性进行权衡: 每种方法的可理解性是如何的?(例如，它的状态空间有多复杂?它是不是有很微妙的影响?)它的可读性如何?读者理解方法和它的含义是否容易?

我们意识到对这种可理解性的分析具有高度的主观性; 尽管如此, 我们使用了两种可以接受的方式. 第一种是众所周知的问题分解: 我们尽可能将问题分解成为若干个互不依赖的, 可解决的, 可被理解的小问题. 例如, 在 Raft 中, 我们把问题分解成为了**领导选取(leader election)**、**日志复制(log replication)**、**安全(safety)**和**成员变化(membership changes)**.

我们采用的第二个方法是通过减少需要考虑的状态的数量, 将状态空间简化, 这能够使得整个系统更加连贯一致, 消除可能的不确定性. Raft 明确定义日志之间不允许出现空洞，并且限制了日志不一致的可能性。尽管在大多数情况下, 我们都在试图消除不确定性, 但是有些情况下不确定性却使算法更易理解. 特别是, 随机化方法引入不确定性, 但是它通过以相似的方式处理所有可能的选择来减少状态空间(choose any; it doesn’t matter). 我们使用随机化来简化 Raft 中的领导选取算法.


## 5 Raft 一致性算法

Raft 是一种用来管理第 2 章中提到的复制日志的算法。表-2 为了方便参考是一个算法的总结版本，表-3 列举了算法中的关键性质；表格中的这些元素将会在这一章剩下的部分中分别进行讨论。

**状态：**

在所有服务器上持久存在的:(在响应远程过程调用 RPC 之前稳定存储的)

| 名称          | 描述                                                         |
| ------------ |:------------------------------------------------------------:|
| currentTerm  | 服务器最后知道的任期号(从0开始递增)                             |
| votedFor     | 在当前任期内收到选票的候选人 id(如果没有就为 null)               |
| log[]        | 日志条目；每个条目包含状态机的要执行命令和从领导人处收到时的任期号 |

<br>
<br>
在所有服务器上不稳定存在的：

| 名称          | 描述                                                         |
| ------------ |:------------------------------------------------------------:|
| commitIndex  | 已知的被提交的最大日志条目的索引值(从0开始递增)                             |
| lastApplied     | 被状态机执行的最大日志条目的索引值(从0开始递增)               |
<br>
<br>
在领导人服务器上不稳定存在的: (在选举之后初始化的)

| 名称          | 描述                                                         |
| ------------ |:------------------------------------------------------------:|
| nextIndex[]  | 对于每一个服务器，记录需要发给它的下一个日志条目的索引(初始化为领导人上一条日志的索引值+1)                             |
| matchIndex[]     | 对于每一个服务器，记录已经复制到该服务器的日志的最高索引值(从0开始递增)               |

<font size=2>表-2-i</font>

**附加日志远程过程调用 (AppendEntries RPC)**

由领导人来调用复制日志(5.3节); 也会用作heartbeat

Functional programming in Scala